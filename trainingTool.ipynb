{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/root/pva-faster-rcnn/lib')\n",
    "sys.path.append('/root/pva-faster-rcnn/lib/datasets')\n",
    "import time\n",
    "from datasets.imdb import imdb\n",
    "import datasets.ds_utils as ds_utils\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import scipy.io as sio\n",
    "import utils.cython_bbox\n",
    "import cPickle\n",
    "import subprocess\n",
    "import uuid\n",
    "from voc_eval import voc_eval\n",
    "from fast_rcnn.config import cfg\n",
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from fast_rcnn.test import im_detect\n",
    "from fast_rcnn.nms_wrapper import nms\n",
    "from utils.timer import Timer\n",
    "import glob\n",
    "import cv2\n",
    "from datasets.config import CLASS_SETS\n",
    "from natsort import natsorted\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonInput = open('./25typesTrain.json','r')\n",
    "annos_25 = json.load(jsonInput)\n",
    "\n",
    "image_path = '/root/data/data-openImages_v4/train'\n",
    "set_num = 0\n",
    "img_pattern = \"{}/*.jpg\".format(image_path)       \n",
    "img_paths = natsorted(glob.glob(img_pattern))\n",
    "\n",
    "target_imgs_25 = [os.path.basename(i)[:-4] for i in img_paths[:500000]]\n",
    "#print target_imgs\n",
    "  \n",
    "    \n",
    "    \n",
    "jsonInput.close()\n",
    "#print original_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonInput = open('/root/data/data-airport/annotations.json','r')\n",
    "annos = json.load(jsonInput)\n",
    "image_path = '/root/data/data-airport/images'\n",
    "set_num = 0\n",
    "\n",
    "\n",
    "img_pattern = \"{}/set0{}/V000/set0{}_V*.jpg\".format(image_path,set_num,set_num)\n",
    "print img_pattern   \n",
    "img_paths = natsorted(glob.glob(img_pattern))\n",
    "target_imgs = [os.path.basename(i)[:-4] for i in img_paths]\n",
    "\n",
    "for index in target_imgs: \n",
    "    set_nuam, v_num, frame = index.split(\"_\")\n",
    "    print frame\n",
    "    bboxes = annos[str(set_num)].get(frame, {}).values()\n",
    "    bboxes = [bbox for bbox in bboxes if bbox['outside']==0 and bbox['occluded']==0]\n",
    "    print bboxes\n",
    "\n",
    "    jsonInput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingConfig = {    \n",
    "    \n",
    "    \n",
    "\n",
    "    \"labelList\":['Backpack','Baseball bat','Baseball glove', 'Bag','Man','Woman',\n",
    "             'Bicycle','Rifle','Handgun','Shotgun','Suit','Gun',\n",
    "             'Dress','Jacket','Skirt','Shorts','Sports Uniform','Shirt','Trousers',\n",
    "             'Mini skirt','Goggles','Glasses','Headphones','Sunglasses',\n",
    "             'Hat','Helmet','Sun hat','Football helmet','Cowboy hat','Sombrero','Roller skates',\n",
    "             'Boot','Handbag','Backpack','Suitcase','Plastic bag','Briefcase','Wheelchair',\n",
    "             'Umbrella','Scarf','Tie'],\n",
    "\n",
    "    u'mapperList':{'Rifle':'Gun','Handgun':'Gun','Shotgun':'Gun','Boy':'Man','Girl':'Woman',\n",
    "              'Mini skirt':'Skirt','Goggles':'Glasses','Sunglasses':'Glasses','Sun hat':'Hat',\n",
    "              'Football helmet':'Helmet','Cowboy hat':'Hat','Sombrero':'Hat','Handbag':'Bag',\n",
    "              'Plastic bag':'Bag','Briefcase':'Bag'}\n",
    "    'gpu_id':'2'\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "with open('test.json', \"w\") as f:\n",
    "    json.dump(trainingConfig,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print '\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix),'\\r';\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "        \n",
    "from time import sleep\n",
    "\n",
    "# A List of Items\n",
    "items = list(range(0, 57))\n",
    "l = len(items)\n",
    "\n",
    "# Initial call to print 0% progress\n",
    "printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "for i, item in enumerate(items):\n",
    "    # Do stuff...\n",
    "    sleep(0.1)\n",
    "    # Update Progress Bar\n",
    "    printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_map(path=\"/root/data\", prefix=\"data-\"):\n",
    "    data_map = {} \n",
    "    data_paths = glob.glob(\"{}/{}*\".format(path, prefix))\n",
    "    for data_path in data_paths:\n",
    "        name = os.path.basename(data_path)[5:]\n",
    "        data_map[name] = data_path\n",
    "    return data_map    \n",
    "\n",
    "data_map = get_data_map()\n",
    "data_names = data_map.keys()\n",
    "    \n",
    "    \n",
    "\n",
    "def has_data(name):\n",
    "    return name in data_names\n",
    "\n",
    "def load_meta(meta_path):\n",
    "    if os.path.exists(meta_path):\n",
    "        meta = json.load(open(meta_path))\n",
    "    else:\n",
    "       \n",
    "        meta = {\"format\":\"jpg\"}\n",
    "        meta[\"train\"] = {\"start\":None, \"end\":None, \"stride\":1, \"sets\":[0]}\n",
    "        meta[\"test\"] = {\"start\":None, \"end\":None, \"stride\":30, \"sets\":[1]}\n",
    "        print(\"Meta data path: {} does not exist. Use Default meta data\".format(meta_path))\n",
    "    return meta\n",
    "\n",
    "class datasetTesting(imdb):\n",
    "    \n",
    "    \n",
    "            \n",
    "    def loadMapper(self,mapperPath,mapperList):\n",
    "        mapper = {}\n",
    "        reverseMapper = {}\n",
    "        f = open(mapperPath,'r')\n",
    "        for i in csv.reader(f):\n",
    "            key = i[0]\n",
    "            if mapperList.has_key(i[1]):\n",
    "                val = mapperList.get(i[1])\n",
    "            else:\n",
    "                val = i[1]\n",
    "            mapper[key] = val\n",
    "            reverseMapper[val] = key\n",
    "        f.close()\n",
    "        return mapper,reverseMapper  \n",
    "    \n",
    "    def getAnnotation(self,labelList,mapperList,sets='train'):\n",
    "        \n",
    "        mapperPath = '/root/data/data-openImages_v4/class-descriptions-boxable.csv'\n",
    "        mapper,reverseMapper = self.loadMapper(mapperPath,mapperList)\n",
    "        method = ['freeform ','xclick']\n",
    "        bboxGTPath = '/root/data/data-openImages_v4/{}-annotations-bbox.csv'.format(sets)\n",
    "        seq = [reverseMapper.get(i) for i in labelList]\n",
    "        f = open(bboxGTPath, 'r')\n",
    "        annotations = {}\n",
    "        mappedClass = {}\n",
    "        for row in csv.reader(f):\n",
    "            if row[1] not in method:\n",
    "                continue\n",
    "            if row[2] not in seq:\n",
    "                continue\n",
    "            if os.path.isfile(os.path.join('/root/data/data-openImages_v4/{}'.format(sets),row[0]+'.jpg')):\n",
    "                if annotations.has_key(row[0]):\n",
    "                    annotations[row[0]] += [row[2:]]\n",
    "                    mappedClass[row[0]] += [[mapper.get(row[2])]+row[3:]]\n",
    "                else:\n",
    "                    annotations[row[0]] = [row[2:]]\n",
    "                    mappedClass[row[0]] = [[mapper.get(row[2])]+row[3:]]\n",
    "        f.close()\n",
    "        return annotations,mappedClass\n",
    "    \n",
    "    def parseConfig(self):\n",
    "        jsonInput = open(self.configPath,'r')\n",
    "        annos = json.load(jsonInput)\n",
    "        CLS_mapper = annos.get(\"CLS_mapper\")\n",
    "        labelList = annos.get(\"labelList\")\n",
    "        jsonInput.close()\n",
    "        return CLS_mapper,labelList\n",
    "    \n",
    "\n",
    "    \n",
    "    def __init__(self, datasetName, annotationPath,configPath):\n",
    "        \n",
    "        name=\"openImages_v4\"\n",
    "        #FOR DEBUGGING\n",
    "        self.debugging = True\n",
    "        \n",
    "        self.configPath = configPath\n",
    "        assert os.path.exists(configPath), \\\n",
    "                'Config path does not exist.: {}'.format(configPath)\n",
    "        self.annotationPath = annotationPath\n",
    "        #os.path.join(self._data_path, \"annotations.json\")         \n",
    "        assert os.path.exists(annotationPath), \\\n",
    "                'Annotation path does not exist.: {}'.format(annotationPath)\n",
    "\n",
    "        imdb.__init__(self,name)\n",
    "        assert data_map.has_key(name),\\\n",
    "        'The {} dataset does not exist. The available dataset are: {}'.format(name, data_map.keys())\n",
    "        \n",
    "        \n",
    "        CLS_mapper,labelList =  self.parseConfig()\n",
    "        print labelList\n",
    "        self._classes = labelList\n",
    "        print self._classes\n",
    "        self.CLS_mapper = CLS_mapper\n",
    "        \n",
    "        namedAnnotation,annotation = self.getAnnotation(self._classes,self.CLS_mapper)\n",
    "        \n",
    "        self._annotation = annotation\n",
    "            \n",
    "        self._data_path = data_map[name]  \n",
    "        assert os.path.exists(self._data_path), \\\n",
    "        'Path does not exist: {}'.format(self._data_path)\n",
    "        \n",
    "        \n",
    "        self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes)))\n",
    "        \n",
    "\n",
    "        \n",
    "        self.original_classes = self.get_original_classes()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        meta_data_path = os.path.join(self._data_path, \"meta.json\")         \n",
    "       \n",
    "            \n",
    "        self._meta = load_meta(meta_data_path)\n",
    "        \n",
    "\n",
    "        self._image_ext = self._meta[\"format\"]    \n",
    "        self._image_ext = '.jpg'\n",
    "        self._image_index = self._get_image_index()\n",
    "\n",
    "        \n",
    "    def get_original_classes(self):\n",
    "        original_classes = set()\n",
    "        for bboxes in self._annotation.values():\n",
    "            original_classes.add(bboxes[0][0])\n",
    "        return original_classes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'has_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-337-70383a507301>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasetTesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/root/pva-faster-rcnn/25typesTrain.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/root/pva-faster-rcnn/test.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-336-887d5b6aef6d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, datasetName, annotationPath, configPath)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLS_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCLS_mapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mnamedAnnotation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLS_mapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_annotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-336-887d5b6aef6d>\u001b[0m in \u001b[0;36mgetAnnotation\u001b[0;34m(self, labelList, mapperList, sets)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmapperPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/root/data/data-openImages_v4/class-descriptions-boxable.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreverseMapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapperPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapperList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'freeform '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'xclick'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mbboxGTPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/root/data/data-openImages_v4/{}-annotations-bbox.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-336-887d5b6aef6d>\u001b[0m in \u001b[0;36mloadMapper\u001b[0;34m(self, mapperPath, mapperList)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mmapperList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapperList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'has_key'"
     ]
    }
   ],
   "source": [
    "a = datasetTesting(\"testing\",\"/root/pva-faster-rcnn/25typesTrain.json\",\"/root/pva-faster-rcnn/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = {\"a\":1}\n",
    "print a.get('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58930\n"
     ]
    }
   ],
   "source": [
    "print sum([14339,450,15425,4307,15910,5580,2919])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
